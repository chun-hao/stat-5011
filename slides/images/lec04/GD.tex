\documentclass[12pt,a4paper]{article}

\usepackage[linesnumbered,ruled,lined]{algorithm2e}

\begin{document}

\begin{algorithm}[H]
    \SetKwInOut{Input}{input}
    \SetKwInOut{Output}{output}

	\Input{initial value $x^{(0)}$, learning rate $\eta$, number of iterations $T$}
	\Output{minimizer $x^{(T)}$}

    \For{$t=0$ \KwTo $T-1$}
    {   
        compute $\Delta x^{(t)} = - \nabla g(x^{(t)})$\\
        $x^{(t + 1)} := x^{(t)} + \eta \Delta x^{(t)}$\\
    }

	% TODO short caption
	\caption{The general gradient descent algorithm.}
\end{algorithm}

\end{document}